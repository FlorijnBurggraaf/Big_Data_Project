{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T10:24:39.856127Z",
     "start_time": "2019-03-14T10:24:39.847073Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install tweepy\n",
    "# !pip install textblob\n",
    "# !python -m textblob.download_corpora\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "############################################################################\n",
    "###########################APPROACH ONE#####################################\n",
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "############################################################################\n",
    "\n",
    "############################################################################\n",
    "###########################APPROACH TWO#####################################\n",
    "#!pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GATHER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "location_tweets = 'PATH'\n",
    "data = open(location_tweets, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = []\n",
    "tweets_file = open(location_tweets, \"r\")\n",
    "\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "        #print (\"Imported tweet created at:\", tweet['created_at'])\n",
    "        #print (\"Tweet content: \\n\", tweet['text'], \"\\n\")\n",
    "    except Exception as e:\n",
    "        print (e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print features of a tweet\n",
    "print (\"Information contained in a single tweet: \\n\")\n",
    "\n",
    "#pprint(tweets_data[0].keys()) # print features horizontally\n",
    "\n",
    "for feature in tweets_data[0].keys(): # print features vertically\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()\n",
    "\n",
    "tweets['feature1'] = list(map(lambda tweet: tweet['feature1'], tweets_data))\n",
    "tweets['feature2'] = list(map(lambda tweet: tweet['feature2'], tweets_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that extracts the hyperlinks from the tweet's content.\n",
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''\n",
    "\n",
    "# A function that checks whether a word is included in the tweet's content\n",
    "def word_in_text(word, text):\n",
    "    word = word.lower()\n",
    "    text = text.lower()\n",
    "    match = re.search(word, text)\n",
    "    if match:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T10:26:08.889395Z",
     "start_time": "2019-03-14T10:26:08.885468Z"
    }
   },
   "source": [
    "# APPROACH ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T10:16:32.999420Z",
     "start_time": "2019-03-14T10:16:32.982536Z"
    }
   },
   "outputs": [],
   "source": [
    "class TwitterClient(object): \n",
    "    '''Generic Twitter Class for sentiment analysis.'''\n",
    "    def __init__(self): \n",
    "        '''Class constructor or initialization method.'''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = 'XXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        consumer_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        access_token = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "        access_token_secret = 'XXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "  \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "  \n",
    "    def clean_tweet(self, tweet): \n",
    "        '''Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements.'''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        '''Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method'''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "  \n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' Main function to fetch tweets and parse them.'''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "  \n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "  \n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "  \n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "  \n",
    "            # return parsed tweets \n",
    "            return tweets \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T10:16:48.023493Z",
     "start_time": "2019-03-14T10:16:46.757434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error : [{'code': 89, 'message': 'Invalid or expired token.'}]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4f585a8d85b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# calling main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-4f585a8d85b5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# picking positive tweets from tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mptweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# percentage of positive tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Positive tweets percentage: {} %\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Donald Trump', count = 200) \n",
    "  \n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    # percentage of neutral tweets \n",
    "    print(\"Neutral tweets percentage: {} %\".format(100*len(tweets - ntweets - ptweets)/len(tweets))) \n",
    "\n",
    "#     # printing first 5 positive tweets \n",
    "#     print(\"\\n\\nPositive tweets:\") \n",
    "#     for tweet in ptweets[:10]: \n",
    "#         print(tweet['text']) \n",
    "  \n",
    "#     # printing first 5 negative tweets \n",
    "#     print(\"\\n\\nNegative tweets:\") \n",
    "#     for tweet in ntweets[:10]: \n",
    "#         print(tweet['text']) \n",
    "\n",
    "if (__name__ == \"__main__\"):  \n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T10:26:27.267432Z",
     "start_time": "2019-03-14T10:26:27.263872Z"
    }
   },
   "source": [
    "# APPROACH TWO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print sentiments \n",
    "# of the sentence. \n",
    "def sentiment_scores(sentence): \n",
    "  \n",
    "    # Create a SentimentIntensityAnalyzer object. \n",
    "    sid_obj = SentimentIntensityAnalyzer() \n",
    "  \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer \n",
    "    # oject gives a sentiment dictionary. \n",
    "    # which contains pos, neg, neu, and compound scores. \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "      \n",
    "    print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\") \n",
    "    print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\") \n",
    "    print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\") \n",
    "  \n",
    "    print(\"Sentence Overall Rated As\", end = \" \") \n",
    "  \n",
    "    # decide sentiment as positive, negative and neutral \n",
    "    if sentiment_dict['compound'] >= 0.05 : \n",
    "        print(\"Positive\") \n",
    "  \n",
    "    elif sentiment_dict['compound'] <= - 0.05 : \n",
    "        print(\"Negative\") \n",
    "  \n",
    "    else : \n",
    "        print(\"Neutral\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driver code \n",
    "if __name__ == \"__main__\" : \n",
    "    \n",
    "    for t i in enumerate(all_tweets):\n",
    "        if i == 10:\n",
    "            break\n",
    "        \n",
    "        sentiment_scores(t) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPROACH 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T12:16:15.382739Z",
     "start_time": "2019-03-14T12:16:15.377166Z"
    }
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "def analyse_sentiment(string):\n",
    "    data = urllib.parse.urlencode({\"text\": string}) \n",
    "    data = data.encode('UTF-8')\n",
    "    \n",
    "    u = urllib.request.urlopen(\"http://text-processing.com/api/sentiment/\", data)\n",
    "    \n",
    "    the_page = u.read()\n",
    "    print(the_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-14T12:16:59.292990Z",
     "start_time": "2019-03-14T12:16:58.955853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x1a0a611e48>\n",
      "b'{\"probability\": {\"neg\": 0.2135799510794848, \"neutral\": 0.13210395192548119, \"pos\": 0.7864200489205152}, \"label\": \"pos\"}'\n"
     ]
    }
   ],
   "source": [
    "analyse_sentiment(\"The cake is delicious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
